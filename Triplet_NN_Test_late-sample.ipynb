{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ratings.csv' dataset consists of \n",
    "- the user who rated the movie (userID)\n",
    "- the movie is rated (movieID)\n",
    "- the rating given by the user for that particular movie (rating)\n",
    "- the time at which the rating was recorded (timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000095, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('ml-25m/ratings.csv')\n",
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'movies.csv' dataset consists of\n",
    "- the movie id (movieID)\n",
    "- the movie title (title)\n",
    "- the genres (genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62423, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie = pd.read_csv('ml-25m/movies.csv')\n",
    "df_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog drugs\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# import the list of stop words from the spacy library\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split(' ') if word.lower() not in STOP_WORDS])\n",
    "\n",
    "print(remove_stop_words('why is my dog on the drugs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genres:\n",
    "\n",
    "# Break up the big genre string into a string array\n",
    "df_movie['genres'] = df_movie['genres'].str.split('|')\n",
    "\n",
    "# Convert genres to string value\n",
    "df_movie['genres'] = df_movie['genres'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Title:\n",
    "\n",
    "# regular expression to extract year and title\n",
    "p1 = re.compile(r'[(](.*?)[)]', re.S)\n",
    "\n",
    "df_movie['title_l'] = df_movie['title'].apply(lambda x: re.findall(r\"[\\w']+\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec(l):\n",
    "    return nlp(remove_stop_words(' '.join(l))).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine movie and rating datasets\n",
    "## Sample a small dataset of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 547145 to 16285937\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   userId     25000 non-null  int64  \n",
      " 1   movieId    25000 non-null  int64  \n",
      " 2   rating     25000 non-null  float64\n",
      " 3   timestamp  25000 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 976.6 KB\n"
     ]
    }
   ],
   "source": [
    "small_data = df_ratings.sample(frac = 0.001)\n",
    "small_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 7)\n",
      "5762 20078\n"
     ]
    }
   ],
   "source": [
    "small_data = pd.merge(small_data, df_movie, how = 'left', on = 'movieId')\n",
    "print(small_data.shape)\n",
    "\n",
    "print(len(set(small_data['movieId'])), len(set(small_data['userId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>title_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3754</td>\n",
       "      <td>3478</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bamba, La (1987)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Bamba, La, 1987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97290</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>[Comedy, Drama, Romance, War]</td>\n",
       "      <td>[Forrest, Gump, 1994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40846</td>\n",
       "      <td>3967</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Billy Elliot (2000)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Billy, Elliot, 2000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155034</td>\n",
       "      <td>1197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>[Action, Adventure, Comedy, Fantasy, Romance]</td>\n",
       "      <td>[Princess, Bride, The, 1987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91517</td>\n",
       "      <td>1222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Full Metal Jacket (1987)</td>\n",
       "      <td>[Drama, War]</td>\n",
       "      <td>[Full, Metal, Jacket, 1987]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                       title  \\\n",
       "0    3754     3478     4.0            Bamba, La (1987)   \n",
       "1   97290      356     5.0         Forrest Gump (1994)   \n",
       "2   40846     3967     4.0         Billy Elliot (2000)   \n",
       "3  155034     1197     5.0  Princess Bride, The (1987)   \n",
       "4   91517     1222     5.0    Full Metal Jacket (1987)   \n",
       "\n",
       "                                          genres                       title_l  \n",
       "0                                        [Drama]             [Bamba, La, 1987]  \n",
       "1                  [Comedy, Drama, Romance, War]         [Forrest, Gump, 1994]  \n",
       "2                                        [Drama]         [Billy, Elliot, 2000]  \n",
       "3  [Action, Adventure, Comedy, Fantasy, Romance]  [Princess, Bride, The, 1987]  \n",
       "4                                   [Drama, War]   [Full, Metal, Jacket, 1987]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.drop(['timestamp'], inplace = True, axis = 1)\n",
    "\n",
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6) (5000, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(small_data, test_size=0.2)\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 4)\n",
      "(2462, 4)\n"
     ]
    }
   ],
   "source": [
    "train_movie_data = train_data[['movieId', 'title', 'title_l', 'genres']].drop_duplicates('movieId')\n",
    "train_movie_data = train_movie_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "\n",
    "print(train_movie_data.shape)\n",
    "\n",
    "test_movie_data = test_data[['movieId', 'title', 'title_l', 'genres']].drop_duplicates('movieId')\n",
    "test_movie_data = test_movie_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "\n",
    "print(test_movie_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual movie content feature: title and genres, two word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 96) (2462, 96)\n"
     ]
    }
   ],
   "source": [
    "train_movie_title_vec = pd.DataFrame(0, index=train_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "train_movie_genre_vec = pd.DataFrame(0, index=train_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "\n",
    "test_movie_title_vec = pd.DataFrame(0, index=test_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "test_movie_genre_vec = pd.DataFrame(0, index=test_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "\n",
    "print(train_movie_title_vec.shape, test_movie_title_vec.shape)\n",
    "\n",
    "# Training\n",
    "for i in range(train_movie_data.shape[0]):\n",
    "    train_movie_title_vec.loc[train_movie_data['movieId'][i], :] = pd.Series(get_word_vec(train_movie_data['title_l'][i]))\n",
    "    train_movie_genre_vec.loc[train_movie_data['movieId'][i], :] = pd.Series(get_word_vec(train_movie_data['genres'][i]))\n",
    "    \n",
    "# Testing\n",
    "for i in range(test_movie_data.shape[0]):\n",
    "    test_movie_title_vec.loc[test_movie_data['movieId'][i], :] = pd.Series(get_word_vec(test_movie_data['title_l'][i]))\n",
    "    test_movie_genre_vec.loc[test_movie_data['movieId'][i], :] = pd.Series(get_word_vec(test_movie_data['genres'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.355089</td>\n",
       "      <td>0.991829</td>\n",
       "      <td>0.153801</td>\n",
       "      <td>-0.195376</td>\n",
       "      <td>-0.939769</td>\n",
       "      <td>1.062713</td>\n",
       "      <td>-0.087003</td>\n",
       "      <td>0.965813</td>\n",
       "      <td>0.811997</td>\n",
       "      <td>0.087335</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.589762</td>\n",
       "      <td>-0.810004</td>\n",
       "      <td>2.363398</td>\n",
       "      <td>1.016425</td>\n",
       "      <td>-1.534584</td>\n",
       "      <td>1.296966</td>\n",
       "      <td>0.531302</td>\n",
       "      <td>-3.913785</td>\n",
       "      <td>-1.275919</td>\n",
       "      <td>-0.685872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.777861</td>\n",
       "      <td>0.856493</td>\n",
       "      <td>-1.002494</td>\n",
       "      <td>0.656409</td>\n",
       "      <td>-0.826132</td>\n",
       "      <td>1.198098</td>\n",
       "      <td>-0.002911</td>\n",
       "      <td>-1.111856</td>\n",
       "      <td>0.393813</td>\n",
       "      <td>-0.333179</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.415740</td>\n",
       "      <td>0.753537</td>\n",
       "      <td>1.899150</td>\n",
       "      <td>1.297991</td>\n",
       "      <td>-2.893570</td>\n",
       "      <td>1.988402</td>\n",
       "      <td>-0.386679</td>\n",
       "      <td>-2.990330</td>\n",
       "      <td>-0.755991</td>\n",
       "      <td>-0.047538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287880</td>\n",
       "      <td>1.461926</td>\n",
       "      <td>0.178619</td>\n",
       "      <td>-0.025045</td>\n",
       "      <td>-1.432144</td>\n",
       "      <td>2.035658</td>\n",
       "      <td>-1.726650</td>\n",
       "      <td>-2.118157</td>\n",
       "      <td>2.140284</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.325660</td>\n",
       "      <td>-0.519488</td>\n",
       "      <td>1.256510</td>\n",
       "      <td>1.914781</td>\n",
       "      <td>-1.083571</td>\n",
       "      <td>1.464755</td>\n",
       "      <td>1.668898</td>\n",
       "      <td>-3.705204</td>\n",
       "      <td>-1.100169</td>\n",
       "      <td>-0.093394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.788493</td>\n",
       "      <td>1.661333</td>\n",
       "      <td>-1.323206</td>\n",
       "      <td>-0.349413</td>\n",
       "      <td>-1.822633</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>-0.922329</td>\n",
       "      <td>-1.570007</td>\n",
       "      <td>0.695472</td>\n",
       "      <td>2.254215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.498176</td>\n",
       "      <td>-1.354960</td>\n",
       "      <td>0.883165</td>\n",
       "      <td>1.006218</td>\n",
       "      <td>-1.923185</td>\n",
       "      <td>-0.453417</td>\n",
       "      <td>-0.569848</td>\n",
       "      <td>-1.409097</td>\n",
       "      <td>-1.022384</td>\n",
       "      <td>-0.884098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.674872</td>\n",
       "      <td>1.723574</td>\n",
       "      <td>0.676185</td>\n",
       "      <td>-0.567428</td>\n",
       "      <td>-1.522431</td>\n",
       "      <td>0.200554</td>\n",
       "      <td>-1.261009</td>\n",
       "      <td>0.501906</td>\n",
       "      <td>0.974284</td>\n",
       "      <td>-1.412346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835550</td>\n",
       "      <td>-1.154070</td>\n",
       "      <td>1.955808</td>\n",
       "      <td>1.720978</td>\n",
       "      <td>-1.634962</td>\n",
       "      <td>1.351146</td>\n",
       "      <td>0.846751</td>\n",
       "      <td>-2.949474</td>\n",
       "      <td>-0.592519</td>\n",
       "      <td>-0.887223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "movieId                                                                         \n",
       "1       -2.355089  0.991829  0.153801 -0.195376 -0.939769  1.062713 -0.087003   \n",
       "2       -1.777861  0.856493 -1.002494  0.656409 -0.826132  1.198098 -0.002911   \n",
       "3       -0.287880  1.461926  0.178619 -0.025045 -1.432144  2.035658 -1.726650   \n",
       "4       -0.788493  1.661333 -1.323206 -0.349413 -1.822633  0.092523 -0.922329   \n",
       "5       -1.674872  1.723574  0.676185 -0.567428 -1.522431  0.200554 -1.261009   \n",
       "\n",
       "               7         8         9   ...        86        87        88  \\\n",
       "movieId                                ...                                 \n",
       "1        0.965813  0.811997  0.087335  ... -1.589762 -0.810004  2.363398   \n",
       "2       -1.111856  0.393813 -0.333179  ... -1.415740  0.753537  1.899150   \n",
       "3       -2.118157  2.140284  0.017525  ... -1.325660 -0.519488  1.256510   \n",
       "4       -1.570007  0.695472  2.254215  ... -0.498176 -1.354960  0.883165   \n",
       "5        0.501906  0.974284 -1.412346  ... -0.835550 -1.154070  1.955808   \n",
       "\n",
       "               89        90        91        92        93        94        95  \n",
       "movieId                                                                        \n",
       "1        1.016425 -1.534584  1.296966  0.531302 -3.913785 -1.275919 -0.685872  \n",
       "2        1.297991 -2.893570  1.988402 -0.386679 -2.990330 -0.755991 -0.047538  \n",
       "3        1.914781 -1.083571  1.464755  1.668898 -3.705204 -1.100169 -0.093394  \n",
       "4        1.006218 -1.923185 -0.453417 -0.569848 -1.409097 -1.022384 -0.884098  \n",
       "5        1.720978 -1.634962  1.351146  0.846751 -2.949474 -0.592519 -0.887223  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_title_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_data_vec = (train_movie_title_vec + train_movie_genre_vec)/2\n",
    "test_movie_data_vec = (test_movie_title_vec + test_movie_genre_vec)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the similarity matrix based on the content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 5211)\n"
     ]
    }
   ],
   "source": [
    "movie_correlation = 1 - pairwise_distances(train_movie_data_vec, metric = 'correlation')\n",
    "movie_correlation[np.isnan(movie_correlation)] = 0\n",
    "print(movie_correlation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.85711685, 0.8821668 , 0.84976041],\n",
       "       [0.85711685, 1.        , 0.75203811, 0.79207242],\n",
       "       [0.8821668 , 0.75203811, 1.        , 0.86057745],\n",
       "       [0.84976041, 0.79207242, 0.86057745, 1.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct co-watched/rated graph for movies\n",
    "An edge exists between two movies if many users rated both movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId\n",
       "0   62216        1\n",
       "1   60962        1\n",
       "2  115090        1\n",
       "3   96463        1\n",
       "4   16367        1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_data = train_data[['userId', 'movieId']]\n",
    "train_user_data = train_user_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "train_user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 20000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_user_data['movieId'])), train_user_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a user dictionary where the key is the movieId and the values are the userIds who rated this movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211\n"
     ]
    }
   ],
   "source": [
    "d_user = {}\n",
    "# \n",
    "for i in range(train_user_data.shape[0]):\n",
    "    if train_user_data['movieId'][i] not in d_user:\n",
    "        d_user[train_user_data['movieId'][i]] = []\n",
    "    else:\n",
    "        d_user[train_user_data['movieId'][i]].append(train_user_data['userId'][i])\n",
    "\n",
    "print(len(d_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create movie-to-movie user co-watched (rated) matrix\n",
    "- cell_{i, j}: # of users who watched/rated both movie i and j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 5211)\n"
     ]
    }
   ],
   "source": [
    "movie_cowatched = np.zeros((len(train_movie_data['movieId']), len(train_movie_data['movieId'])))\n",
    "\n",
    "for r in range(movie_cowatched.shape[0]):\n",
    "    for c in range(r+1, movie_cowatched.shape[1]):\n",
    "        movie_cowatched[r, c] = len(set(d_user[train_movie_data['movieId'][r]]\\\n",
    "                                ).intersection(set(d_user[ train_movie_data['movieId'][c]])))\n",
    "\n",
    "# Symmetric matrix for co-watched movie matrix\n",
    "movie_cowatched.T.sum(), movie_cowatched.sum()\n",
    "movie_cowatched_s = movie_cowatched + movie_cowatched.T\n",
    "\n",
    "print(movie_cowatched_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_cowatched_s[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877.0, (5211, 5211))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_cowatched.sum(), movie_cowatched.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDML: Triplet NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of all movie pairs with # of cowatched > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873 [(0, 773), (0, 932), (0, 1158), (0, 1608), (0, 1660)]\n"
     ]
    }
   ],
   "source": [
    "cowatched_list = []\n",
    "# Getting the list of all pairs with # of cowatched > 0\n",
    "for r in range(movie_cowatched_s.shape[0]):\n",
    "    for c in range(r+1, movie_cowatched_s.shape[1]):\n",
    "        if movie_cowatched_s[r, c] > 0:\n",
    "            cowatched_list.append((r, c))\n",
    "            \n",
    "print(len(cowatched_list), cowatched_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dictionary with key = movieId, and values = set of index who have # of cowatched = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cowatched_dict = {}\n",
    "\n",
    "for r in range(movie_cowatched_s.shape[0]):\n",
    "    zero_cowatched_dict[r] = set(c for c in range(movie_cowatched_s.shape[0]) \\\n",
    "                              if movie_cowatched_s[r, c] == 0 and r != c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 96) (2462, 96)\n"
     ]
    }
   ],
   "source": [
    "x_train_movie_title = train_movie_title_vec.values\n",
    "x_train_movie_genre = train_movie_genre_vec.values\n",
    "\n",
    "x_test_movie_title = test_movie_title_vec.values\n",
    "x_test_movie_genre = test_movie_genre_vec.values\n",
    "\n",
    "print(x_train_movie_title.shape, x_test_movie_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.35508943,  0.9918291 ,  0.15380089, -0.1953755 ],\n",
       "       [-1.77786136,  0.85649323, -1.00249374,  0.65640938],\n",
       "       [-0.28787977,  1.46192575,  0.17861867, -0.0250445 ],\n",
       "       [-0.78849339,  1.66133308, -1.32320559, -0.34941271]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_movie_title[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_triplet(x_train_movie, cowatched_list, zero_cowatched_dict, ap_pairs, an_pairs, testsize):\n",
    " \n",
    "    #ap_pairs, an_pairs = 10, 10\n",
    "    #testsize = 0.2 \n",
    "\n",
    "    trainsize = 1 - testsize\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "\n",
    "    A_P_pairs = random.sample(cowatched_list, k = ap_pairs)\n",
    "    Neg_idx = []\n",
    "    for p in range(len(A_P_pairs)):\n",
    "        Neg_idx.append(sample(zero_cowatched_dict[A_P_pairs[p][0]].intersection(zero_cowatched_dict[A_P_pairs[p][1]]), 1)[0])\n",
    "\n",
    "    # Train\n",
    "    A_P_len = len(A_P_pairs)\n",
    "    Neg_len = len(Neg_idx)\n",
    "    train_i = 0\n",
    "    for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "        # print(ap, train_i)\n",
    "        Anchor = x_train_movie[ap[0]]\n",
    "        Positive = x_train_movie[ap[1]]\n",
    "        Negative = x_train_movie[Neg_idx[train_i]]\n",
    "        triplet_train_pairs.append([Anchor, Positive, Negative])\n",
    "        train_i += 1\n",
    "\n",
    "    # Test\n",
    "    test_i = int(A_P_len*trainsize)\n",
    "    for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "        #print(ap, test_i)\n",
    "        Anchor = x_train_movie[ap[0]]\n",
    "        Positive = x_train_movie[ap[1]]\n",
    "        Negative = x_train_movie[Neg_idx[test_i]]\n",
    "        triplet_test_pairs.append([Anchor, Positive, Negative])\n",
    "        test_i += 1\n",
    "    \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 3, 96), (200, 3, 96))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title, X_test_title = generate_triplet(x_train_movie_title, cowatched_list, zero_cowatched_dict, \\\n",
    "                                   ap_pairs=1000, an_pairs=1000,testsize=0.2)\n",
    "\n",
    "X_train_genre, X_test_genre = generate_triplet(x_train_movie_genre, cowatched_list, zero_cowatched_dict, \\\n",
    "                                   ap_pairs=1000, an_pairs=1000,testsize=0.2)\n",
    "\n",
    "X_train_title.shape, X_test_title.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a ranking Triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(256,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(96,name='embeddings')) # No activation on final dense layer\n",
    "    # model.add(Lambda(lambda x: tf.math.l2_normalize(x, axis = 1))) # L2 normalize embeddings\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer_2/concat:0\", shape=(None, 288), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "anchor_input = Input((96,1,1,), name='anchor_input')\n",
    "positive_input = Input((96,1,1,), name='positive_input')\n",
    "negative_input = Input((96,1,1,), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network([96,1,1,])\n",
    "# Shared_DNN = create_base_network([12,8,1,])\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 96)           1415776     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 288)          0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "                                                                 sequential_3[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,415,776\n",
      "Trainable params: 1,415,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3999 - val_loss: 0.3989\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3972 - val_loss: 0.3988\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3947 - val_loss: 0.3986\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3919 - val_loss: 0.3984\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3888 - val_loss: 0.3980\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3847 - val_loss: 0.3975\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3804 - val_loss: 0.3968\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3747 - val_loss: 0.3956\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3686 - val_loss: 0.3939\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3612 - val_loss: 0.3911\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3522 - val_loss: 0.3876\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3415 - val_loss: 0.3836\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3306 - val_loss: 0.3794\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3191 - val_loss: 0.3770\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3072 - val_loss: 0.3768\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2949 - val_loss: 0.3771\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2824 - val_loss: 0.3765\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2692 - val_loss: 0.3766\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2563 - val_loss: 0.3767\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2427 - val_loss: 0.3763\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2299 - val_loss: 0.3763\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2172 - val_loss: 0.3771\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2051 - val_loss: 0.3782\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1927 - val_loss: 0.3798\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.1804 - val_loss: 0.3820\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1678 - val_loss: 0.3839\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.1561 - val_loss: 0.3858\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.1440 - val_loss: 0.3877\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1327 - val_loss: 0.3906\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1217 - val_loss: 0.3934\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1109 - val_loss: 0.3965\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0994 - val_loss: 0.4000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0889 - val_loss: 0.4025\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0787 - val_loss: 0.4045\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0691 - val_loss: 0.4072\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0608 - val_loss: 0.4104\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0532 - val_loss: 0.4134\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0455 - val_loss: 0.4162\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0394 - val_loss: 0.4186\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0336 - val_loss: 0.4208\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0284 - val_loss: 0.4228\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0229 - val_loss: 0.4250\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0188 - val_loss: 0.4255\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0141 - val_loss: 0.4263\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0110 - val_loss: 0.4275\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0085 - val_loss: 0.4300\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0065 - val_loss: 0.4327\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0049 - val_loss: 0.4355\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0035 - val_loss: 0.4388\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0025 - val_loss: 0.4410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a64ee6f50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time consuming\n",
    "# (1) Movie title tower\n",
    "\n",
    "Anchor = X_train_title[:,0,:].reshape(-1,96,1,1)\n",
    "Positive = X_train_title[:,1,:].reshape(-1,96,1,1)\n",
    "Negative = X_train_title[:,2,:].reshape(-1,96,1,1)\n",
    "Anchor_test = X_test_title[:,0,:].reshape(-1,96,1,1)\n",
    "Positive_test = X_test_title[:,1,:].reshape(-1,96,1,1)\n",
    "Negative_test = X_test_title[:,2,:].reshape(-1,96,1,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 96) (2462, 96)\n"
     ]
    }
   ],
   "source": [
    "trained_model1 = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "\n",
    "x_train_title_pred = trained_model1.predict(x_train_movie_title.reshape(-1, 96, 1, 1))\n",
    "x_test_title_pred = trained_model1.predict(x_test_movie_title.reshape(-1, 96, 1, 1))\n",
    "\n",
    "print(x_train_title_pred.shape, x_test_title_pred.shape)\n",
    "\n",
    "# print(len(x_test_title_pred[0]), np.sqrt((x_test_title_pred[0]**2).sum())) # L2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer_2/concat:0\", shape=(None, 288), dtype=float32)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 96)           1415776     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 288)          0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "                                                                 sequential_3[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,415,776\n",
      "Trainable params: 1,415,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model2.compile(loss=triplet_loss, optimizer=adam_optim)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.5647 - val_loss: 0.4704\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4275 - val_loss: 0.4099\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3710 - val_loss: 0.3821\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3395 - val_loss: 0.3712\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3308 - val_loss: 0.3594\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3164 - val_loss: 0.3544\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3082 - val_loss: 0.3555\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3004 - val_loss: 0.3533\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2921 - val_loss: 0.3549\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2861 - val_loss: 0.3554\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2753 - val_loss: 0.3565\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2706 - val_loss: 0.3564\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2643 - val_loss: 0.3550\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2578 - val_loss: 0.3564\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2546 - val_loss: 0.3600\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2488 - val_loss: 0.3635\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2440 - val_loss: 0.3682\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2403 - val_loss: 0.3707\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2343 - val_loss: 0.3722\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2309 - val_loss: 0.3734\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2270 - val_loss: 0.3722\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2207 - val_loss: 0.3707\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2180 - val_loss: 0.3720\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2137 - val_loss: 0.3734\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2101 - val_loss: 0.3746\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2060 - val_loss: 0.3768\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2020 - val_loss: 0.3763\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1988 - val_loss: 0.3753\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1939 - val_loss: 0.3737\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1900 - val_loss: 0.3754\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1869 - val_loss: 0.3784\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1828 - val_loss: 0.3813\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1782 - val_loss: 0.3838\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1762 - val_loss: 0.3865\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1724 - val_loss: 0.3881\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1694 - val_loss: 0.3888\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1663 - val_loss: 0.3897\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.1634 - val_loss: 0.3904\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1608 - val_loss: 0.3907\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1570 - val_loss: 0.3949\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1539 - val_loss: 0.4019\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1521 - val_loss: 0.4076\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1487 - val_loss: 0.4090\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1472 - val_loss: 0.4086\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1433 - val_loss: 0.4099\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1402 - val_loss: 0.4059\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1383 - val_loss: 0.4059\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1351 - val_loss: 0.4100\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.1328 - val_loss: 0.4136\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1303 - val_loss: 0.4190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a65297810>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time consuming\n",
    "# Movie genre tower\n",
    "Anchor = X_train_genre[:,0,:].reshape(-1,96,1,1)\n",
    "Positive = X_train_genre[:,1,:].reshape(-1,96,1,1)\n",
    "Negative = X_train_genre[:,2,:].reshape(-1,96,1,1)\n",
    "Anchor_test = X_test_genre[:,0,:].reshape(-1,96,1,1)\n",
    "Positive_test = X_test_genre[:,1,:].reshape(-1,96,1,1)\n",
    "Negative_test = X_test_genre[:,2,:].reshape(-1,96,1,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model2.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 96) (2462, 96)\n"
     ]
    }
   ],
   "source": [
    "trained_model2 = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "\n",
    "x_train_genre_pred = trained_model2.predict(x_train_movie_genre.reshape(-1, 96, 1, 1))\n",
    "x_test_genre_pred = trained_model2.predict(x_test_movie_genre.reshape(-1, 96, 1, 1))\n",
    "\n",
    "print(x_train_genre_pred.shape, x_test_genre_pred.shape)\n",
    "\n",
    "# print(len(x_test_movie_pred[0]), np.sqrt((x_test_movie_pred[0]**2).sum())) # L2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine movie title embedding vector and genre embedding vector via element-wise multiplication, then apply L2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.01920007,  0.02746626,  0.23426566, -0.34349748],\n",
       "        [ 0.07480142,  0.05476695,  0.16217682, -0.20209655],\n",
       "        [ 0.23435155,  0.1969838 ,  0.2182913 , -0.04982473],\n",
       "        [ 0.01382559,  0.11908623,  0.36122996, -0.30534092]],\n",
       "       dtype=float32),\n",
       " array([[ 0.16780746,  0.4363753 , -0.10361842,  0.21908543],\n",
       "        [-0.03771356,  0.2611343 , -0.17115346,  0.10339521],\n",
       "        [ 0.03289174,  0.46348557,  0.02858389,  0.2581252 ],\n",
       "        [ 0.0230694 ,  0.32935804, -0.0991705 ,  0.04588554]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_genre_pred[:4, :4], x_train_title_pred[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 96)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_title_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 0.99999994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_train_movie_pred = x_train_title_pred * x_train_genre_pred\n",
    "x_train_movie_pred = normalize(x_train_movie_pred, axis = 1, norm = 'l2')\n",
    "print(len(x_train_movie_pred[0]), np.sqrt((x_train_movie_pred[0]**2).sum())) # L2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similary matrix based on the embedding movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_correlation_tripletNN = 1 - pairwise_distances(x_train_movie_pred, metric = 'correlation')\n",
    "movie_correlation_tripletNN[np.isnan(movie_correlation_tripletNN)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.85711685, 0.8821668 , 0.84976041],\n",
       "       [0.85711685, 1.        , 0.75203811, 0.79207242],\n",
       "       [0.8821668 , 0.75203811, 1.        , 0.86057745],\n",
       "       [0.84976041, 0.79207242, 0.86057745, 1.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.77347115, 0.80596001, 0.77832601],\n",
       "       [0.77347115, 1.        , 0.6199472 , 0.6548749 ],\n",
       "       [0.80596001, 0.6199472 , 1.        , 0.77751269],\n",
       "       [0.77832601, 0.6548749 , 0.77751269, 1.        ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation_tripletNN[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>title_l</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Toy, Story, 1995]</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Jumanji, 1995]</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Grumpier, Old, Men, 1995]</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Waiting, to, Exhale, 1995]</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Father, of, the, Bride, Part, II, 1995]</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                    title_l  \\\n",
       "0                        [Toy, Story, 1995]   \n",
       "1                           [Jumanji, 1995]   \n",
       "2                [Grumpier, Old, Men, 1995]   \n",
       "3               [Waiting, to, Exhale, 1995]   \n",
       "4  [Father, of, the, Bride, Part, II, 1995]   \n",
       "\n",
       "                                              genres  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1-dimensional array with movie title\n",
    "titles = train_movie_data[['title', 'genres']]\n",
    "indices = pd.Series(train_movie_data.index, index = train_movie_data['title'])\n",
    "\n",
    "# Function that get movie recommendations\n",
    "# method: 'standard', 'tripletNN'\n",
    "def movie_recommendations(title, movie_corr, movie_cowatched_s, method = 'tripletNN', k = 20):\n",
    "    print(method)\n",
    "    print(titles[titles['title'] == title])\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(movie_corr[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:(k+1)]\n",
    "     \n",
    "    rel_scores = [movie_cowatched_s[idx, j] for j in [i[0] for i in sim_scores]]\n",
    "    print(rel_scores)\n",
    "\n",
    "    DCG_k = sum([(2**i[1] - 1)/(np.log2((i[0]+1)+1)) \\\n",
    "                 for i in list(enumerate(rel_scores))])\n",
    "    IDCG_k = sum([(2**i[1] - 1)/(np.log2((i[0]+1)+1)) \\\n",
    "                  for i in list(enumerate(sorted(rel_scores, reverse=True)))])\n",
    "    NDCG_k = DCG_k/(IDCG_k+0.0001)\n",
    "    print(NDCG_k)\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices], NDCG_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard\n",
      "         title                     genres\n",
      "5  Heat (1995)  [Action, Crime, Thriller]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "standard_RS_lists = movie_recommendations('Heat (1995)', \\\n",
    "                      movie_correlation, movie_cowatched_s, method = 'standard', k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>Heat, The (2013)</td>\n",
       "      <td>[Action, Comedy, Crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Shaft (2000)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Rock, The (1996)</td>\n",
       "      <td>[Action, Adventure, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Shaft (1971)</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Body Heat (1981)</td>\n",
       "      <td>[Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>Punisher, The (2004)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>Get the Gringo (2012)</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Batman (1989)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Ronin (1998)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>Rookie, The (1990)</td>\n",
       "      <td>[Action, Comedy, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                            genres\n",
       "4541       Heat, The (2013)           [Action, Comedy, Crime]\n",
       "2015           Shaft (2000)         [Action, Crime, Thriller]\n",
       "464        Rock, The (1996)     [Action, Adventure, Thriller]\n",
       "2004           Shaft (1971)  [Action, Crime, Drama, Thriller]\n",
       "1638       Body Heat (1981)                 [Crime, Thriller]\n",
       "3076   Punisher, The (2004)         [Action, Crime, Thriller]\n",
       "4411  Get the Gringo (2012)  [Action, Crime, Drama, Thriller]\n",
       "405           Batman (1989)         [Action, Crime, Thriller]\n",
       "1285           Ronin (1998)         [Action, Crime, Thriller]\n",
       "2930     Rookie, The (1990)        [Action, Comedy, Thriller]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_RS_lists[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tripletNN\n",
      "               title                   genres\n",
      "4871  Sicario (2015)  [Crime, Drama, Mystery]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "tripletNN_RS_lists = movie_recommendations('Sicario (2015)', \\\n",
    "                      movie_correlation_tripletNN, movie_cowatched_s, method = 'tripletNN', k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>Gone Baby Gone (2007)</td>\n",
       "      <td>[Crime, Drama, Mystery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>Galaxy Express 999 (Ginga tetsudÃ´ Three-Nine) ...</td>\n",
       "      <td>[Adventure, Animation, Fantasy, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>Fantastic Four (2005)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>Star Trek Beyond (2016)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>Mystic River (2003)</td>\n",
       "      <td>[Crime, Drama, Mystery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>Duel (1971)</td>\n",
       "      <td>[Action, Mystery, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Alfie (2004)</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>The Call Up (2016)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Bat Whispers, The (1930)</td>\n",
       "      <td>[Crime, Drama, Mystery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>Lucky Number Slevin (2006)</td>\n",
       "      <td>[Crime, Drama, Mystery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "3789                              Gone Baby Gone (2007)   \n",
       "3956  Galaxy Express 999 (Ginga tetsudÃ´ Three-Nine) ...   \n",
       "3455                              Fantastic Four (2005)   \n",
       "4846                            Star Trek Beyond (2016)   \n",
       "2943                                Mystic River (2003)   \n",
       "3291                                        Duel (1971)   \n",
       "3246                                       Alfie (2004)   \n",
       "4982                                 The Call Up (2016)   \n",
       "1758                           Bat Whispers, The (1930)   \n",
       "3567                         Lucky Number Slevin (2006)   \n",
       "\n",
       "                                       genres  \n",
       "3789                  [Crime, Drama, Mystery]  \n",
       "3956  [Adventure, Animation, Fantasy, Sci-Fi]  \n",
       "3455              [Action, Adventure, Sci-Fi]  \n",
       "4846              [Action, Adventure, Sci-Fi]  \n",
       "2943                  [Crime, Drama, Mystery]  \n",
       "3291              [Action, Mystery, Thriller]  \n",
       "3246                 [Comedy, Drama, Romance]  \n",
       "4982              [Action, Adventure, Sci-Fi]  \n",
       "1758                  [Crime, Drama, Mystery]  \n",
       "3567                  [Crime, Drama, Mystery]  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripletNN_RS_lists[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[movie_cowatched.sum(axis = 1)> 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action', 'Mystery', 'Thriller']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripletNN_RS_lists[0].iloc[5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
