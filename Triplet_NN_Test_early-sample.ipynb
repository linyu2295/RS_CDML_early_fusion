{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ratings.csv' dataset consists of \n",
    "- the user who rated the movie (userID)\n",
    "- the movie is rated (movieID)\n",
    "- the rating given by the user for that particular movie (rating)\n",
    "- the time at which the rating was recorded (timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000095, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('ml-25m/ratings.csv')\n",
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'movies.csv' dataset consists of\n",
    "- the movie id (movieID)\n",
    "- the movie title (title)\n",
    "- the genres (genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62423, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie = pd.read_csv('ml-25m/movies.csv')\n",
    "df_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog drugs\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# import the list of stop words from the spacy library\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split(' ') if word.lower() not in STOP_WORDS])\n",
    "\n",
    "print(remove_stop_words('why is my dog on the drugs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genres:\n",
    "\n",
    "# Break up the big genre string into a string array\n",
    "df_movie['genres'] = df_movie['genres'].str.split('|')\n",
    "\n",
    "# Convert genres to string value\n",
    "df_movie['genres'] = df_movie['genres'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Title:\n",
    "\n",
    "# regular expression to extract year and title\n",
    "p1 = re.compile(r'[(](.*?)[)]', re.S)\n",
    "\n",
    "df_movie['title_l'] = df_movie['title'].apply(lambda x: re.findall(r\"[\\w']+\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec(l):\n",
    "    return nlp(remove_stop_words(' '.join(l))).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine movie and rating datasets\n",
    "## Sample a small dataset of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 2962376 to 14277444\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   userId     25000 non-null  int64  \n",
      " 1   movieId    25000 non-null  int64  \n",
      " 2   rating     25000 non-null  float64\n",
      " 3   timestamp  25000 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 976.6 KB\n"
     ]
    }
   ],
   "source": [
    "small_data = df_ratings.sample(frac = 0.001)\n",
    "small_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 7)\n",
      "5786 19967\n"
     ]
    }
   ],
   "source": [
    "small_data = pd.merge(small_data, df_movie, how = 'left', on = 'movieId')\n",
    "print(small_data.shape)\n",
    "\n",
    "print(len(set(small_data['movieId'])), len(set(small_data['userId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>title_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19534</td>\n",
       "      <td>3031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Repossessed (1990)</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[Repossessed, 1990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62797</td>\n",
       "      <td>5013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gosford Park (2001)</td>\n",
       "      <td>[Comedy, Drama, Mystery]</td>\n",
       "      <td>[Gosford, Park, 2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123140</td>\n",
       "      <td>650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Moll Flanders (1996)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Moll, Flanders, 1996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8950</td>\n",
       "      <td>7317</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EuroTrip (2004)</td>\n",
       "      <td>[Adventure, Comedy]</td>\n",
       "      <td>[EuroTrip, 2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126523</td>\n",
       "      <td>8865</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sky Captain and the World of Tomorrow (2004)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "      <td>[Sky, Captain, and, the, World, of, Tomorrow, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                                         title  \\\n",
       "0   19534     3031     1.0                            Repossessed (1990)   \n",
       "1   62797     5013     5.0                           Gosford Park (2001)   \n",
       "2  123140      650     3.0                          Moll Flanders (1996)   \n",
       "3    8950     7317     2.5                               EuroTrip (2004)   \n",
       "4  126523     8865     4.0  Sky Captain and the World of Tomorrow (2004)   \n",
       "\n",
       "                        genres  \\\n",
       "0                     [Comedy]   \n",
       "1     [Comedy, Drama, Mystery]   \n",
       "2                      [Drama]   \n",
       "3          [Adventure, Comedy]   \n",
       "4  [Action, Adventure, Sci-Fi]   \n",
       "\n",
       "                                             title_l  \n",
       "0                                [Repossessed, 1990]  \n",
       "1                              [Gosford, Park, 2001]  \n",
       "2                             [Moll, Flanders, 1996]  \n",
       "3                                   [EuroTrip, 2004]  \n",
       "4  [Sky, Captain, and, the, World, of, Tomorrow, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.drop(['timestamp'], inplace = True, axis = 1)\n",
    "\n",
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6) (5000, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(small_data, test_size=0.2)\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 4)\n",
      "(2507, 4)\n"
     ]
    }
   ],
   "source": [
    "train_movie_data = train_data[['movieId', 'title', 'title_l', 'genres']].drop_duplicates('movieId')\n",
    "train_movie_data = train_movie_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "\n",
    "print(train_movie_data.shape)\n",
    "\n",
    "test_movie_data = test_data[['movieId', 'title', 'title_l', 'genres']].drop_duplicates('movieId')\n",
    "test_movie_data = test_movie_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "\n",
    "print(test_movie_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 96) (2507, 96)\n"
     ]
    }
   ],
   "source": [
    "train_movie_data_vec = pd.DataFrame(0, index=train_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "\n",
    "test_movie_data_vec = pd.DataFrame(0, index=test_movie_data['movieId'], \n",
    "                                   columns=range(96))\n",
    "\n",
    "print(train_movie_data_vec.shape, test_movie_data_vec.shape)\n",
    "\n",
    "for i in range(train_movie_data.shape[0]):\n",
    "    tmp_content = train_movie_data['title_l'][i] + train_movie_data['genres'][i]\n",
    "    train_movie_data_vec.loc[train_movie_data['movieId'][i], :] = pd.Series(get_word_vec(tmp_content))\n",
    "    \n",
    "for i in range(test_movie_data.shape[0]):\n",
    "    tmp_content = test_movie_data['title_l'][i] + test_movie_data['genres'][i]\n",
    "    test_movie_data_vec.loc[test_movie_data['movieId'][i], :] = pd.Series(get_word_vec(tmp_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.544457</td>\n",
       "      <td>1.982641</td>\n",
       "      <td>-1.609174</td>\n",
       "      <td>-0.832535</td>\n",
       "      <td>0.706813</td>\n",
       "      <td>0.843196</td>\n",
       "      <td>-1.082757</td>\n",
       "      <td>0.479867</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>-1.350987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.389453</td>\n",
       "      <td>-0.612897</td>\n",
       "      <td>3.257624</td>\n",
       "      <td>1.612306</td>\n",
       "      <td>-0.675844</td>\n",
       "      <td>0.680780</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>-2.220095</td>\n",
       "      <td>-1.026240</td>\n",
       "      <td>-0.928899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.251009</td>\n",
       "      <td>1.858588</td>\n",
       "      <td>-2.274010</td>\n",
       "      <td>-0.327125</td>\n",
       "      <td>1.166850</td>\n",
       "      <td>0.634994</td>\n",
       "      <td>-0.510081</td>\n",
       "      <td>-0.884999</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>-1.454704</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.407658</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>2.621021</td>\n",
       "      <td>1.749237</td>\n",
       "      <td>-0.923112</td>\n",
       "      <td>0.679678</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>-1.344364</td>\n",
       "      <td>-0.602621</td>\n",
       "      <td>-1.191469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.025808</td>\n",
       "      <td>2.101699</td>\n",
       "      <td>-0.808080</td>\n",
       "      <td>-0.662055</td>\n",
       "      <td>0.155747</td>\n",
       "      <td>1.403549</td>\n",
       "      <td>-1.099139</td>\n",
       "      <td>-1.171176</td>\n",
       "      <td>1.717982</td>\n",
       "      <td>-0.008322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.931525</td>\n",
       "      <td>-0.423738</td>\n",
       "      <td>2.268520</td>\n",
       "      <td>2.035343</td>\n",
       "      <td>-1.238552</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>1.313296</td>\n",
       "      <td>-2.841366</td>\n",
       "      <td>-0.805220</td>\n",
       "      <td>0.286188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.167611</td>\n",
       "      <td>2.240464</td>\n",
       "      <td>-2.007942</td>\n",
       "      <td>-1.945721</td>\n",
       "      <td>-0.125155</td>\n",
       "      <td>-0.174539</td>\n",
       "      <td>-1.665239</td>\n",
       "      <td>-0.648345</td>\n",
       "      <td>0.702949</td>\n",
       "      <td>0.822510</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.039095</td>\n",
       "      <td>-0.407382</td>\n",
       "      <td>2.383182</td>\n",
       "      <td>1.146705</td>\n",
       "      <td>-1.876704</td>\n",
       "      <td>-1.051628</td>\n",
       "      <td>-0.027557</td>\n",
       "      <td>-1.542852</td>\n",
       "      <td>-0.727483</td>\n",
       "      <td>0.113651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.563130</td>\n",
       "      <td>2.395524</td>\n",
       "      <td>-0.576473</td>\n",
       "      <td>-1.212703</td>\n",
       "      <td>-1.081023</td>\n",
       "      <td>-0.059765</td>\n",
       "      <td>-1.371703</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.818381</td>\n",
       "      <td>-1.087977</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169376</td>\n",
       "      <td>-0.157378</td>\n",
       "      <td>2.914577</td>\n",
       "      <td>2.291084</td>\n",
       "      <td>-1.752722</td>\n",
       "      <td>0.494840</td>\n",
       "      <td>0.904072</td>\n",
       "      <td>-2.267776</td>\n",
       "      <td>-0.628808</td>\n",
       "      <td>-0.172327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "movieId                                                                         \n",
       "1       -0.544457  1.982641 -1.609174 -0.832535  0.706813  0.843196 -1.082757   \n",
       "2       -0.251009  1.858588 -2.274010 -0.327125  1.166850  0.634994 -0.510081   \n",
       "3       -1.025808  2.101699 -0.808080 -0.662055  0.155747  1.403549 -1.099139   \n",
       "4       -1.167611  2.240464 -2.007942 -1.945721 -0.125155 -0.174539 -1.665239   \n",
       "5       -1.563130  2.395524 -0.576473 -1.212703 -1.081023 -0.059765 -1.371703   \n",
       "\n",
       "               7         8         9   ...        86        87        88  \\\n",
       "movieId                                ...                                 \n",
       "1        0.479867  0.455717 -1.350987  ... -1.389453 -0.612897  3.257624   \n",
       "2       -0.884999  0.006366 -1.454704  ... -1.407658 -0.058199  2.621021   \n",
       "3       -1.171176  1.717982 -0.008322  ... -0.931525 -0.423738  2.268520   \n",
       "4       -0.648345  0.702949  0.822510  ... -1.039095 -0.407382  2.383182   \n",
       "5        0.085500  0.818381 -1.087977  ... -1.169376 -0.157378  2.914577   \n",
       "\n",
       "               89        90        91        92        93        94        95  \n",
       "movieId                                                                        \n",
       "1        1.612306 -0.675844  0.680780  0.795322 -2.220095 -1.026240 -0.928899  \n",
       "2        1.749237 -0.923112  0.679678  0.854836 -1.344364 -0.602621 -1.191469  \n",
       "3        2.035343 -1.238552  0.012303  1.313296 -2.841366 -0.805220  0.286188  \n",
       "4        1.146705 -1.876704 -1.051628 -0.027557 -1.542852 -0.727483  0.113651  \n",
       "5        2.291084 -1.752722  0.494840  0.904072 -2.267776 -0.628808 -0.172327  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_data_vec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the similarity matrix based on the content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 5226)\n"
     ]
    }
   ],
   "source": [
    "movie_correlation = 1 - pairwise_distances(train_movie_data_vec, metric = 'correlation')\n",
    "movie_correlation[np.isnan(movie_correlation)] = 0\n",
    "print(movie_correlation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.89710642, 0.89283011, 0.86406222],\n",
       "       [0.89710642, 1.        , 0.80089332, 0.81801318],\n",
       "       [0.89283011, 0.80089332, 1.        , 0.87170862],\n",
       "       [0.86406222, 0.81801318, 0.87170862, 1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct co-watched/rated graph for movies\n",
    "An edge exists between two movies if many users rated both movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId\n",
       "0  126892        1\n",
       "1   39467        1\n",
       "2  113178        1\n",
       "3   47064        1\n",
       "4  124628        1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_data = train_data[['userId', 'movieId']]\n",
    "train_user_data = train_user_data.sort_values(by = 'movieId').reset_index(drop = True)\n",
    "train_user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5226, 20000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_user_data['movieId'])), train_user_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a user dictionary where the key is the movieId and the values are the userIds who rated this movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5226\n"
     ]
    }
   ],
   "source": [
    "d_user = {}\n",
    "# \n",
    "for i in range(train_user_data.shape[0]):\n",
    "    if train_user_data['movieId'][i] not in d_user:\n",
    "        d_user[train_user_data['movieId'][i]] = []\n",
    "    else:\n",
    "        d_user[train_user_data['movieId'][i]].append(train_user_data['userId'][i])\n",
    "\n",
    "print(len(d_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create movie-to-movie user co-watched (rated) matrix\n",
    "- cell_{i, j}: # of users who watched/rated both movie i and j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 5226)\n"
     ]
    }
   ],
   "source": [
    "movie_cowatched = np.zeros((len(train_movie_data['movieId']), len(train_movie_data['movieId'])))\n",
    "\n",
    "for r in range(movie_cowatched.shape[0]):\n",
    "    for c in range(r+1, movie_cowatched.shape[1]):\n",
    "        movie_cowatched[r, c] = len(set(d_user[train_movie_data['movieId'][r]]\\\n",
    "                                ).intersection(set(d_user[ train_movie_data['movieId'][c]])))\n",
    "\n",
    "# Symmetric matrix for co-watched movie matrix\n",
    "movie_cowatched.T.sum(), movie_cowatched.sum()\n",
    "movie_cowatched_s = movie_cowatched + movie_cowatched.T\n",
    "\n",
    "print(movie_cowatched_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_cowatched_s[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846.0, (5226, 5226))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_cowatched.sum(), movie_cowatched.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDML: Triplet NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of all movie pairs with # of cowatched > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845 [(0, 575), (0, 699), (0, 1654), (4, 889), (4, 1459)]\n"
     ]
    }
   ],
   "source": [
    "cowatched_list = []\n",
    "# Getting the list of all pairs with # of cowatched > 0\n",
    "for r in range(movie_cowatched_s.shape[0]):\n",
    "    for c in range(r+1, movie_cowatched_s.shape[1]):\n",
    "        if movie_cowatched_s[r, c] > 0:\n",
    "            cowatched_list.append((r, c))\n",
    "            \n",
    "print(len(cowatched_list), cowatched_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dictionary with key = movieId, and values = set of index who have # of cowatched = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cowatched_dict = {}\n",
    "\n",
    "for r in range(movie_cowatched_s.shape[0]):\n",
    "    zero_cowatched_dict[r] = set(c for c in range(movie_cowatched_s.shape[0]) \\\n",
    "                              if movie_cowatched_s[r, c] == 0 and r != c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 96) (2507, 96)\n"
     ]
    }
   ],
   "source": [
    "x_train_movie = train_movie_data_vec.values\n",
    "x_test_movie = test_movie_data_vec.values\n",
    "\n",
    "print(x_train_movie.shape, x_test_movie.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5444566 ,  1.9826405 , -1.60917366, -0.83253467],\n",
       "       [-0.25100935,  1.8585875 , -2.27401018, -0.32712525],\n",
       "       [-1.02580774,  2.10169935, -0.80807978, -0.6620546 ],\n",
       "       [-1.167611  ,  2.24046421, -2.0079422 , -1.94572103]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_movie[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_triplet(cowatched_list, zero_cowatched_dict, ap_pairs, an_pairs, testsize):\n",
    " \n",
    "    #ap_pairs, an_pairs = 10, 10\n",
    "    #testsize = 0.2 \n",
    "\n",
    "    trainsize = 1 - testsize\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "\n",
    "    A_P_pairs = random.sample(cowatched_list, k = ap_pairs)\n",
    "    Neg_idx = []\n",
    "    for p in range(len(A_P_pairs)):\n",
    "        Neg_idx.append(sample(zero_cowatched_dict[A_P_pairs[p][0]].intersection(zero_cowatched_dict[A_P_pairs[p][1]]), 1)[0])\n",
    "\n",
    "    # Train\n",
    "    A_P_len = len(A_P_pairs)\n",
    "    Neg_len = len(Neg_idx)\n",
    "    train_i = 0\n",
    "    for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "        # print(ap, train_i)\n",
    "        Anchor = x_train_movie[ap[0]]\n",
    "        Positive = x_train_movie[ap[1]]\n",
    "        Negative = x_train_movie[Neg_idx[train_i]]\n",
    "        triplet_train_pairs.append([Anchor, Positive, Negative])\n",
    "        train_i += 1\n",
    "\n",
    "    # Test\n",
    "    test_i = int(A_P_len*trainsize)\n",
    "    for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "        #print(ap, test_i)\n",
    "        Anchor = x_train_movie[ap[0]]\n",
    "        Positive = x_train_movie[ap[1]]\n",
    "        Negative = x_train_movie[Neg_idx[test_i]]\n",
    "        triplet_test_pairs.append([Anchor, Positive, Negative])\n",
    "        test_i += 1\n",
    "    \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 3, 96), (200, 3, 96))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = generate_triplet(cowatched_list, zero_cowatched_dict, \\\n",
    "                                   ap_pairs=1000, an_pairs=1000,testsize=0.2)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a ranking Triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(256,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(96,name='embeddings')) # No activation on final dense layer\n",
    "    model.add(Lambda(lambda x: tf.math.l2_normalize(x, axis = 1)))\n",
    "    # L2 normalize embeddings\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(None, 288), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "anchor_input = Input((96,1,1,), name='anchor_input')\n",
    "positive_input = Input((96,1,1,), name='positive_input')\n",
    "negative_input = Input((96,1,1,), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network([96,1,1,])\n",
    "# Shared_DNN = create_base_network([12,8,1,])\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 96, 1, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 96)           1415776     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 288)          0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,415,776\n",
      "Trainable params: 1,415,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3883 - val_loss: 0.3598\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3406 - val_loss: 0.3508\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3007 - val_loss: 0.3399\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2711 - val_loss: 0.3531\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2287 - val_loss: 0.3490\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1963 - val_loss: 0.3415\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1653 - val_loss: 0.3478\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1346 - val_loss: 0.3461\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.1098 - val_loss: 0.3617\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0891 - val_loss: 0.3630\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0714 - val_loss: 0.3562\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0557 - val_loss: 0.3476\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0434 - val_loss: 0.3575\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0329 - val_loss: 0.3667\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0230 - val_loss: 0.3435\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0194 - val_loss: 0.3541\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0115 - val_loss: 0.3746\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0092 - val_loss: 0.3610\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0074 - val_loss: 0.3517\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0053 - val_loss: 0.3532\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0038 - val_loss: 0.3478\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.3513\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0016 - val_loss: 0.3597\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0017 - val_loss: 0.3567\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0012 - val_loss: 0.3528\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 8.9656e-04 - val_loss: 0.3572\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 6.9087e-04 - val_loss: 0.3604\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 7.3136e-04 - val_loss: 0.3566\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 2.5966e-04 - val_loss: 0.3520\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 2.9633e-04 - val_loss: 0.3500\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 7.9303e-04 - val_loss: 0.3558\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 1.6308e-04 - val_loss: 0.3529\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 5.1198e-04 - val_loss: 0.3482\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 3.6797e-04 - val_loss: 0.3493\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 1.6444e-05 - val_loss: 0.3513\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 2.5334e-04 - val_loss: 0.3505\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 5.3163e-04 - val_loss: 0.3507\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 1.7320e-04 - val_loss: 0.3525\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 1.8379e-04 - val_loss: 0.3558\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 1.6682e-04 - val_loss: 0.3571\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 5.2279e-05 - val_loss: 0.3551\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 5.0510e-05 - val_loss: 0.3508\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 1.5784e-04 - val_loss: 0.3474\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 2.5525e-04 - val_loss: 0.3486\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 5.7400e-05 - val_loss: 0.3515\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 6.4780e-05 - val_loss: 0.3523\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 1.2710e-04 - val_loss: 0.3568\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 7.6777e-05 - val_loss: 0.3588\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 1.0534e-05 - val_loss: 0.3597\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 8.0879e-05 - val_loss: 0.3603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b82036810>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time consuming\n",
    "\n",
    "Anchor = X_train[:,0,:].reshape(-1,96,1,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,96,1,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,96,1,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,96,1,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,96,1,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,96,1,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 96) (2507, 96)\n",
      "96 0.99999994\n"
     ]
    }
   ],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "\n",
    "x_train_movie_pred = trained_model.predict(x_train_movie.reshape(-1, 96, 1, 1))\n",
    "x_test_movie_pred = trained_model.predict(x_test_movie.reshape(-1, 96, 1, 1))\n",
    "\n",
    "print(x_train_movie_pred.shape, x_test_movie_pred.shape)\n",
    "\n",
    "print(len(x_test_movie_pred[0]), np.sqrt((x_test_movie_pred[0]**2).sum())) # L2-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similary matrix based on the embedding movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_correlation_tripletNN = 1 - pairwise_distances(x_train_movie_pred, metric = 'correlation')\n",
    "movie_correlation_tripletNN[np.isnan(movie_correlation_tripletNN)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.89710642, 0.89283011, 0.86406222],\n",
       "       [0.89710642, 1.        , 0.80089332, 0.81801318],\n",
       "       [0.89283011, 0.80089332, 1.        , 0.87170862],\n",
       "       [0.86406222, 0.81801318, 0.87170862, 1.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.35811315, 0.49267136, 0.2441658 ],\n",
       "       [0.35811315, 1.        , 0.16613979, 0.11602336],\n",
       "       [0.49267136, 0.16613979, 1.        , 0.26052436],\n",
       "       [0.2441658 , 0.11602336, 0.26052436, 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_correlation_tripletNN[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>title_l</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Toy, Story, 1995]</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Jumanji, 1995]</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Grumpier, Old, Men, 1995]</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Waiting, to, Exhale, 1995]</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Father, of, the, Bride, Part, II, 1995]</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                    title_l  \\\n",
       "0                        [Toy, Story, 1995]   \n",
       "1                           [Jumanji, 1995]   \n",
       "2                [Grumpier, Old, Men, 1995]   \n",
       "3               [Waiting, to, Exhale, 1995]   \n",
       "4  [Father, of, the, Bride, Part, II, 1995]   \n",
       "\n",
       "                                              genres  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1-dimensional array with movie title\n",
    "titles = train_movie_data[['title', 'genres']]\n",
    "indices = pd.Series(train_movie_data.index, index = train_movie_data['title'])\n",
    "\n",
    "# Function that get movie recommendations\n",
    "# method: 'standard', 'tripletNN'\n",
    "def movie_recommendations(title, movie_corr, movie_cowatched_s, method = 'tripletNN', k = 20):\n",
    "    print(method)\n",
    "    print(titles[titles['title'] == title])\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(movie_corr[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:(k+1)]\n",
    "     \n",
    "    rel_scores = [movie_cowatched_s[idx, j] for j in [i[0] for i in sim_scores]]\n",
    "    print(rel_scores)\n",
    "\n",
    "    DCG_k = sum([(2**i[1] - 1)/(np.log2((i[0]+1)+1)) \\\n",
    "                 for i in list(enumerate(rel_scores))])\n",
    "    IDCG_k = sum([(2**i[1] - 1)/(np.log2((i[0]+1)+1)) \\\n",
    "                  for i in list(enumerate(sorted(rel_scores, reverse=True)))])\n",
    "    NDCG_k = DCG_k/(IDCG_k+0.0001)\n",
    "    print(NDCG_k)\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices], NDCG_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard\n",
      "         title                     genres\n",
      "5  Heat (1995)  [Action, Crime, Thriller]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "standard_RS_lists = movie_recommendations('Heat (1995)', \\\n",
    "                      movie_correlation, movie_cowatched_s, method = 'standard', k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>Shaft (2000)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>Punisher, The (2004)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Ronin (1998)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Batman (1989)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>Thursday (1998)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>Hostage (2005)</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Judgment Night (1993)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>Someone to Watch Over Me (1987)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>Kite (1998)</td>\n",
       "      <td>[Action, Animation, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Face/Off (1997)</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                                genres\n",
       "2037                     Shaft (2000)             [Action, Crime, Thriller]\n",
       "3076             Punisher, The (2004)             [Action, Crime, Thriller]\n",
       "1279                     Ronin (1998)             [Action, Crime, Thriller]\n",
       "399                     Batman (1989)             [Action, Crime, Thriller]\n",
       "3350                  Thursday (1998)             [Action, Crime, Thriller]\n",
       "3433                   Hostage (2005)      [Action, Crime, Drama, Thriller]\n",
       "325             Judgment Night (1993)             [Action, Crime, Thriller]\n",
       "1661  Someone to Watch Over Me (1987)             [Action, Crime, Thriller]\n",
       "4854                      Kite (1998)  [Action, Animation, Crime, Thriller]\n",
       "923                   Face/Off (1997)      [Action, Crime, Drama, Thriller]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_RS_lists[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tripletNN\n",
      "               title                   genres\n",
      "4876  Sicario (2015)  [Crime, Drama, Mystery]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "tripletNN_RS_lists = movie_recommendations('Sicario (2015)', \\\n",
    "                      movie_correlation_tripletNN, movie_cowatched_s, method = 'tripletNN', k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>Lady in the Water (2006)</td>\n",
       "      <td>[Drama, Fantasy, Mystery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>Beverly Hills Cop II (1987)</td>\n",
       "      <td>[Action, Comedy, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Road Warrior, The (Mad Max 2) (1981)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>Lake House, The (2006)</td>\n",
       "      <td>[Drama, Fantasy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2 (...</td>\n",
       "      <td>[Action, Adventure, Drama, Fantasy, Mystery, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Kangaroo Jack (2003)</td>\n",
       "      <td>[Action, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>Inception (2010)</td>\n",
       "      <td>[Action, Crime, Drama, Mystery, Sci-Fi, Thrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>Spider-Man 3 (2007)</td>\n",
       "      <td>[Action, Adventure, Sci-Fi, Thriller, IMAX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>RoboCop 3 (1993)</td>\n",
       "      <td>[Action, Crime, Drama, Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "3630                           Lady in the Water (2006)   \n",
       "2435                              Monsters, Inc. (2001)   \n",
       "2180                        Beverly Hills Cop II (1987)   \n",
       "2013               Road Warrior, The (Mad Max 2) (1981)   \n",
       "3624                             Lake House, The (2006)   \n",
       "4313  Harry Potter and the Deathly Hallows: Part 2 (...   \n",
       "2732                               Kangaroo Jack (2003)   \n",
       "4180                                   Inception (2010)   \n",
       "3750                                Spider-Man 3 (2007)   \n",
       "355                                    RoboCop 3 (1993)   \n",
       "\n",
       "                                                 genres  \n",
       "3630                          [Drama, Fantasy, Mystery]  \n",
       "2435  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "2180                  [Action, Comedy, Crime, Thriller]  \n",
       "2013              [Action, Adventure, Sci-Fi, Thriller]  \n",
       "3624                          [Drama, Fantasy, Romance]  \n",
       "4313  [Action, Adventure, Drama, Fantasy, Mystery, I...  \n",
       "2732                                   [Action, Comedy]  \n",
       "4180  [Action, Crime, Drama, Mystery, Sci-Fi, Thrill...  \n",
       "3750        [Action, Adventure, Sci-Fi, Thriller, IMAX]  \n",
       "355            [Action, Crime, Drama, Sci-Fi, Thriller]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripletNN_RS_lists[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[movie_cowatched.sum(axis = 1)> 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
